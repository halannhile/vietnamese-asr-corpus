{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text preprocessing: \n",
    "* lowercase all words \n",
    "* remove special characters \n",
    "* remove line breaks \n",
    "* expand all numbers and other characters: e.g. 18% - muoi tam phan tram, 20/10/2024 (ngay hai muoi thang muoi nam hai ngan khong tram muoi bon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from vietnam_number import n2w\n",
    "\n",
    "# Specify the path to the input text file\n",
    "input_file_path = \"./original_transcript/recording1.txt\"\n",
    "\n",
    "# Extract the directory and base filename without extension\n",
    "directory, filename = os.path.split(input_file_path)\n",
    "base_filename, _ = os.path.splitext(filename)\n",
    "\n",
    "# Specify the path for the new processed text file\n",
    "output_directory = \"./original_transcript/processed_transcript\"\n",
    "output_file_path = os.path.join(output_directory, f\"{base_filename}.txt\")\n",
    "\n",
    "# Read the contents of the text file\n",
    "with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "    input_text = file.read()\n",
    "\n",
    "# Task 1: Lowercase all words\n",
    "lowercased_text = input_text.lower()\n",
    "\n",
    "# Task 2: Remove all non-letter characters (except numbers, %, and dates)\n",
    "# Preserve characters with Vietnamese tone marks\n",
    "non_letter_pattern = r'[^a-zA-Z0-9%\\/àáảãạâầấẩẫậăằắẳẵặèéẻẽẹêềếểễệđìíỉĩịòóỏõọôồốổỗộơờớởỡợùúủũụưừứửữựỳýỷỹỵ]+'\n",
    "letters_and_numbers_text = re.sub(non_letter_pattern, ' ', lowercased_text)\n",
    "\n",
    "# Task 3: Remove all line breaks\n",
    "cleaned_text = re.sub(r'\\n', ' ', letters_and_numbers_text)\n",
    "\n",
    "# Task 4: Replace numbers with their full form using vietnam_number\n",
    "def replace_numbers(match):\n",
    "    number = match.group(0)\n",
    "    return n2w(number)\n",
    "\n",
    "# Replace numbers with their full form\n",
    "expanded_text = re.sub(r'\\b\\d+\\b', replace_numbers, cleaned_text)\n",
    "\n",
    "# Task 5: Convert dates\n",
    "def replace_date(match):\n",
    "    date = match.group(0)\n",
    "    day, month, year = date.split('/')\n",
    "    \n",
    "    day_text = n2w(day)  # Convert day to written form using vietnam_number\n",
    "    month_text = [\n",
    "        'tháng một', 'tháng hai', 'tháng ba', 'tháng tư', 'tháng năm', 'tháng sáu',\n",
    "        'tháng bảy', 'tháng tám', 'tháng chín', 'tháng mười', 'tháng mười một', 'tháng mười hai'\n",
    "    ][int(month) - 1]  # Choose the month text\n",
    "    year_text = 'năm ' + n2w(year)  # Convert year to written form using vietnam_number\n",
    "    \n",
    "    return f'ngày {day_text} {month_text} {year_text}'\n",
    "\n",
    "# Replace dates with the desired format\n",
    "date_pattern = r'\\b\\d{1,2}/\\d{1,2}/\\d{4}\\b'\n",
    "expanded_text = re.sub(date_pattern, replace_date, expanded_text)\n",
    "\n",
    "# Task 6: Add a space between numbers and \"%\" symbols\n",
    "expanded_text = re.sub(r'%', r' phần trăm', expanded_text)\n",
    "\n",
    "# Save the processed text into a new file\n",
    "with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "    file.write(expanded_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 1: generate textgrid where the speech segments' transcriptions are empty (i.e. main purpose is to split original wav file into smaller speech segments, the alignment of audio and transcription is not important at this step)\n",
    "* decrease energy threshold will make the resulting speech segments longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from praatio import tgio\n",
    "import soundfile as sf\n",
    "from auditok import split\n",
    "import os\n",
    "\n",
    "# wav: wave signal (a table with all the frames extracted from the signal), sr: sampled rate\n",
    "wav, sr = sf.read(\"./speech_corpus/recording1.wav\")\n",
    "# split region into speech segments, default energy_threshold is 50. increase = longer speech segments \n",
    "energy_threshold = 10\n",
    "region = split(\"./speech_corpus/recording1.wav\", energy_threshold=energy_threshold)\n",
    "\n",
    "# duration in seconds\n",
    "duration = len(wav)/sr\n",
    "\n",
    "# Create a directory for the corresponding energy_threshold if it doesn't exist\n",
    "# output_directory = f\"./mfa_data/auditok/{energy_threshold}\"\n",
    "output_directory = \"./speech_corpus\"\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Initialize blank Textgrid object\n",
    "tg = tgio.Textgrid()\n",
    "entryList = []\n",
    "\n",
    "# The region stores all timestamps in the wav file where there is speech\n",
    "# You can iterate through the region to get starts and ends of elements (speech segments) and annotate\n",
    "for elt in region: \n",
    "    entry = tgio.Interval(elt.meta.start, elt.meta.end, \"*\")\n",
    "    entryList.append(entry)\n",
    "\n",
    "# \"str\": name of IntervalTier, 0 - duration: covering the entire duration of the audio\n",
    "tier = tgio.IntervalTier(\"str\", entryList, 0, duration)\n",
    "tg.addTier(tier)\n",
    "output_textgrid = os.path.join(output_directory, \"recording1.TextGrid\")\n",
    "tg.save(output_textgrid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 2: using the output from Montreal Force Aligner on the original, long .wav file, we try to populate the transcription of the textgrid created in part 1 with the transcription from the MFA's textgrid, and the original, long transcription file of the .wav audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from praatio import tgio\n",
    "import os\n",
    "\n",
    "# Define the path to the input TextGrid\n",
    "input_textgrid_path = \"./mfa_aligned_textgrid/recording1.TextGrid\"\n",
    "\n",
    "# Load the TextGrid with individual words\n",
    "word_tg = tgio.openTextgrid(input_textgrid_path)\n",
    "\n",
    "# Construct the path to the segmented speech TextGrid with the same base filename and energy_threshold\n",
    "speech_textgrid_path = f\"./split_textgrid/recording1.TextGrid\"\n",
    "\n",
    "# Load the TextGrid with segmented speech regions\n",
    "speech_tg = tgio.openTextgrid(speech_textgrid_path)\n",
    "\n",
    "# Extract the base filename (without extension) from the input TextGrid path\n",
    "base_filename = os.path.splitext(os.path.basename(input_textgrid_path))[0]\n",
    "\n",
    "# Construct the output folder path with the current energy_threshold\n",
    "output_folder = f\"./combined_textgrid/\"\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Construct the output TextGrid path with the same filename\n",
    "output_textgrid_path = os.path.join(output_folder, f\"{base_filename}.TextGrid\")\n",
    "\n",
    "# Create a new TextGrid to store the combined information\n",
    "combined_tg = tgio.Textgrid()\n",
    "\n",
    "# Copy the minimum and maximum timestamps from the segmented speech TextGrid\n",
    "combined_tg.minTimestamp = speech_tg.minTimestamp\n",
    "combined_tg.maxTimestamp = speech_tg.maxTimestamp\n",
    "\n",
    "# Initialize a list to store the entries for the new TextGrid\n",
    "new_entries = []\n",
    "\n",
    "# Iterate through intervals in the segmented speech TextGrid\n",
    "for speech_interval in speech_tg.tierDict[\"str\"].entryList:\n",
    "    speech_start = speech_interval[0]\n",
    "    speech_end = speech_interval[1]\n",
    "\n",
    "    # Convert speech_start and speech_end to float\n",
    "    speech_start_float = float(speech_start)\n",
    "    speech_end_float = float(speech_end)\n",
    "\n",
    "    # Find words that fall within the speech segment\n",
    "    words_in_segment = []\n",
    "    for word_interval in word_tg.tierDict[\"words\"].entryList:\n",
    "        word_start = float(word_interval[0])\n",
    "        word_end = float(word_interval[1])\n",
    "\n",
    "        # Check if the word_interval overlaps with the speech segment\n",
    "        if speech_start_float <= word_end and speech_end_float >= word_start:\n",
    "            words_in_segment.append(word_interval[2])\n",
    "\n",
    "    # Combine words into a single string\n",
    "    combined_words = \" \".join(words_in_segment)\n",
    "\n",
    "    # Create a new entry for the combined TextGrid\n",
    "    new_entry = tgio.Interval(speech_start, speech_end, combined_words)\n",
    "    new_entries.append(new_entry)\n",
    "\n",
    "# Create a new tier in the combined TextGrid\n",
    "combined_tier = tgio.IntervalTier(\"speech_segments\", new_entries, combined_tg.minTimestamp, combined_tg.maxTimestamp)\n",
    "\n",
    "# Add the new tier to the combined TextGrid\n",
    "combined_tg.addTier(combined_tier)\n",
    "\n",
    "# Save the combined TextGrid with the same filename as the input TextGrid\n",
    "combined_tg.save(output_textgrid_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 3: split into .wav files and their corresponding .txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from praatio import tgio\n",
    "import soundfile as sf\n",
    "import os\n",
    "\n",
    "# Define the paths to the TextGrid and WAV files\n",
    "textgrid_path = \"./combined_textgrid/recording1.TextGrid\"\n",
    "wav_path = \"./speech_corpus/recording1.wav\"\n",
    "\n",
    "# Extract the base filename (without extension) from the WAV file\n",
    "base_filename = os.path.splitext(os.path.basename(wav_path))[0]\n",
    "\n",
    "# Create the output folder based on the base filename and energy_threshold\n",
    "output_folder = os.path.join(\"./asr_corpus\", base_filename)\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Load the TextGrid\n",
    "textgrid = tgio.openTextgrid(textgrid_path)\n",
    "\n",
    "# Load the WAV file and its sample rate\n",
    "wav_data, sample_rate = sf.read(wav_path)\n",
    "\n",
    "# Initialize segment counter\n",
    "segment_counter = 1\n",
    "\n",
    "# Iterate through intervals in the TextGrid\n",
    "for tier_name in textgrid.tierNameList:\n",
    "    tier = textgrid.tierDict[tier_name]\n",
    "\n",
    "    for interval in tier.entryList:\n",
    "        start_time = interval[0]\n",
    "        end_time = interval[1]\n",
    "        transcription = interval[2]\n",
    "\n",
    "        # Check if the interval is non-empty and at least 2 seconds\n",
    "        if transcription.strip() and end_time - start_time >= 2.0:\n",
    "            # Extract the segment from the WAV data\n",
    "            start_sample = int(start_time * sample_rate)\n",
    "            end_sample = int(end_time * sample_rate)\n",
    "            segment = wav_data[start_sample:end_sample]\n",
    "\n",
    "            # Define the filenames for the segment within the subfolder\n",
    "            wav_filename = os.path.join(output_folder, f\"{base_filename}_segment{segment_counter}.wav\")\n",
    "            txt_filename = os.path.join(output_folder, f\"{base_filename}_segment{segment_counter}.txt\")\n",
    "\n",
    "            # Save the segment as a WAV file\n",
    "            sf.write(wav_filename, segment, sample_rate)\n",
    "\n",
    "            # Save the transcription as a text file\n",
    "            with open(txt_filename, \"w\", encoding=\"utf-8\") as txt_file:\n",
    "                txt_file.write(transcription)\n",
    "\n",
    "            segment_counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
